# Three-Machine Architecture

Complete infrastructure documentation across all 3 machines in the Clawdbot ecosystem.

> **Last updated**: January 2025 ‚Äî Reasoning-first models, swap protection, cross-machine fallback

---

## üñ•Ô∏è Machine 1: MacBook Pro (48GB RAM) ‚Äî Orchestrator

**Role**: Main session (Claude Opus), heavy sub-agent compute, orchestration

### Ollama Models
| Model | Size | Purpose |
|-------|------|---------|
| **qwen3:8b** | 5.2 GB | **PRIMARY** for sub-agents/heartbeats (reasoning=true) |
| devstral-small-2:24b | 15 GB | Heavy coding tasks (48GB RAM safe) |
| gpt-oss:20b | 13 GB | General tasks fallback |

### Clawdbot Config
| Setting | Value |
|---------|-------|
| **Main model** | `anthropic/claude-opus-4-5` |
| **Fallbacks** | Sonnet ‚Üí qwen3:8b ‚Üí devstral-24b ‚Üí gpt-oss:20b |
| **Heartbeat** | `ollama/qwen3:8b` (reasoning=true, via Mac Mini, **FREE**) |
| **Sub-agents** | `ollama/qwen3:8b` (reasoning=true) ‚Üí `ollama-macbook/devstral-small-2:24b` ‚Üí `ollama/gpt-oss:20b` ‚Üí Sonnet ‚Üí Opus |
| **Thinking** | `thinkingDefault: "low"` (Opus always thinks) |

### Services
- **Clawdbot Gateway** ‚Äî AI orchestrator (port 18789+)
- **Ollama** ‚Äî Local LLM inference (port 11434, launchd)
- **event-watcher.sh** ‚Äî Self-healing bash loop (launchd, 60s interval)
- **Bash cleanup scripts** ‚Äî macbook-cleanup.sh (launchd, 15 min)

### Self-Healing
- **event-watcher.sh** (60s loop) ‚Äî Monitors Ollama, pm2, zombies, simulators
- **Cleaner Bot** (hourly cron) ‚Äî Deep cleanup (caches, temp files, disk)
- **Healer Bot** (hourly cron) ‚Äî Read event logs, diagnose, smart healing

### Network
- **Hostname**: `felipes-macbook-pro-2.local`
- **Tailscale IP**: `100.125.165.107`
- **Ollama URL**: `http://felipes-macbook-pro-2.local:11434`
- **Ports**: 11434 (Ollama), 18789+ (Clawdbot)

---

## üñ•Ô∏è Machine 2: Mac Mini (16GB RAM) ‚Äî Always-On Server

**Role**: **CENTRAL BRAIN** ‚Äî Always-on services, heartbeats, Ollama hub for all machines, game servers

### Ollama Models

‚ö†Ô∏è **CRITICAL: Mac Mini has only 16GB RAM!**

| Model | Size | Purpose | Status |
|-------|------|---------|--------|
| **qwen3:8b** | 5.2 GB | **PRIMARY** model (reasoning=true, safe for 16GB RAM) | ‚úÖ Always loaded |
| gpt-oss:20b | 13 GB | On-demand fallback (DeepSeek-V3, causes swap) | ‚ö†Ô∏è NOT kept loaded |
| qwen3-fast:8b | 5.2 GB | Faster variant for quick responses | Optional |

**Swap Protection:**
- gpt-oss:20b (14GB) was causing **15.6GB swap** ‚Äî SWAP DEATH
- Primary changed to qwen3:8b (5GB) ‚Äî safe for 16GB
- Healer Bot v3 monitors swap and auto-unloads heavy models
- desired-state.json has resource_limits: swap_warn_gb=8, critical=12, max_loaded_model_gb=6

### Clawdbot Config
| Setting | Value |
|---------|-------|
| **Main model** | `ollama/qwen3:8b` (reasoning=true, **FREE**) |
| **Fallbacks** | `ollama/gpt-oss:20b` (on-demand) ‚Üí `ollama-macbook/qwen3:8b` ‚Üí Sonnet ‚Üí Opus |
| **Heartbeat** | `ollama/qwen3:8b` (reasoning=true, **FREE**) |
| **Sub-agents** | `ollama/qwen3:8b` (reasoning=true) ‚Üí `ollama/gpt-oss:20b` ‚Üí Sonnet ‚Üí Opus |
| **Thinking** | `thinkingDefault: "low"` (qwen3:8b with reasoning=true) |

### Services
- **Clawdbot Gateway** ‚Äî AI orchestrator (port 18789)
- **Ollama** ‚Äî Local LLM inference (port 11434, Homebrew service)
- **pm2** ‚Äî Process manager for game servers
- **clawd-monitor** ‚Äî Bot dashboard (port 9009)

### pm2 Processes
| Process | Port | Description |
|---------|------|-------------|
| aphos-server-prod | 2567 | Aphos game server (production) |
| aphos-server-dev | 2568 | Aphos game server (development) |

### Agents
- **main** ‚Äî Primary Clawdbot agent
- **aphos** ‚Äî Game server management bot
- **shitcoin-bot** ‚Äî Trading research bot

### Session Data
- **64 session files** ‚Äî Persistent sessions for all projects
- Sessions survive reboots via pm2 and tmux

### Network
- **Hostname**: `felipes-mac-mini.local`
- **Tailscale IP**: `100.115.10.14`
- **Ollama URL**: `http://felipes-mac-mini.local:11434`
- **Ports**: 11434 (Ollama), 18789 (Clawdbot), 9009 (clawd-monitor), 2567-2568 (Aphos)

---

## üñ•Ô∏è Machine 3: Windows MSI ‚Äî Dedicated Windows Bot

**Role**: Windows-specific automation tasks  
**Identity**: "Clawdbot Master Windows" üñ•Ô∏è

### Ollama Models
- ‚ùå **No local Ollama** ‚Äî Routes ALL inference through Mac Mini via Tailscale

### Clawdbot Config
| Setting | Value |
|---------|-------|
| **Main model** | `anthropic/claude-opus-4-5` |
| **Fallbacks** | `ollama-macmini/qwen3:8b` (reasoning=true) ‚Üí Sonnet ‚Üí Opus |
| **Heartbeat** | `ollama-macmini/qwen3:8b` (reasoning=true, via Mac Mini, **FREE**) |
| **Sub-agents** | `ollama-macmini/qwen3:8b` (reasoning=true) ‚Üí Sonnet ‚Üí Opus |
| **Ollama provider** | `ollama-macmini` ‚Üí `http://100.115.10.14:11434` |
| **Auto-start** | Windows Scheduled Task "ClawdbotGateway" (runs on login) |
| **Thinking** | `thinkingDefault: "low"` (Opus always thinks) |

### Architecture Flow
```
Windows MSI ‚Üí Mac Mini Ollama (100.115.10.14:11434)
                    ‚Üì (if needed)
              MacBook Ollama (felipes-macbook-pro-2.local:11434)
                    ‚Üì (last resort)
              Claude API (Sonnet ‚Üí Opus)
```

### ‚úÖ Credit Leak FIXED
Previously 100% Claude-powered. Now routes through Mac Mini's Ollama via Tailscale ‚Äî **FREE local inference** for most tasks.

### Network
- **Tailscale IP**: `100.67.241.32`
- **SSH**: `ssh msi` from both Macs (SOCKS proxy through Tailscale)
- **User**: `felip`
- **Note**: Both Macs use Tailscale in userspace-networking mode (SOCKS5 on `localhost:1055`)

---

## üåê Network Topology

```
MacBook Pro (48GB) ‚Üê‚îÄ‚îÄlocal network‚îÄ‚îÄ‚Üí Mac Mini (16GB) ‚Üê CENTRAL BRAIN
       ‚Üï                                    ‚Üï
    Tailscale                           Tailscale
       ‚Üï                                    ‚Üï
Windows MSI ‚îÄ‚îÄ‚îÄOllama via Tailscale‚îÄ‚îÄ‚îÄ‚Üí Mac Mini (100.115.10.14:11434)

Heartbeat routing (reasoning-first):
  MacBook  ‚Üí Mac Mini Ollama (qwen3:8b, reasoning=true)
  Mac Mini ‚Üí Local Ollama (qwen3:8b, reasoning=true)
  Windows  ‚Üí Mac Mini Ollama via Tailscale (qwen3:8b, reasoning=true)

Cross-machine fallback (NEW):
  Mac Mini Ollama fails ‚Üí MacBook Ollama catches it
  MacBook Ollama fails ‚Üí Mac Mini Ollama catches it
  Automatic failover, zero downtime
```

### Tailscale IPs

| Device | IP | Role |
|--------|----|------|
| MacBook Pro | `100.125.165.107` | Orchestrator |
| Mac Mini | `100.115.10.14` | Always-on server |
| Windows MSI | `100.67.241.32` | Windows bot |
| iPhone | `100.89.50.26` | Mobile access |

### SSH Access
```bash
# MacBook ‚Üí Mac Mini
ssh felipemacmini@felipes-mac-mini.local

# MacBook ‚Üí Windows MSI
ssh msi  # Uses SOCKS proxy through Tailscale

# Mac Mini ‚Üí Windows MSI
ssh msi  # Same SOCKS proxy config
```

### Cross-Machine Ollama Access
```bash
# MacBook ‚Üí Mac Mini Ollama
curl http://felipes-mac-mini.local:11434/api/tags
curl http://100.115.10.14:11434/api/tags  # Tailscale

# Mac Mini ‚Üí MacBook Ollama
curl http://felipes-macbook-pro-2.local:11434/api/tags
curl http://100.125.165.107:11434/api/tags  # Tailscale
```

---

## üí∞ Cost Analysis by Machine

| Machine | Local Models | API Usage | Monthly Estimate |
|---------|-------------|-----------|-----------------|
| MacBook Pro | ‚úÖ 3 models (FREE compute) | Opus for main session | $50-100 |
| Mac Mini | ‚úÖ 3 models (FREE compute) | Minimal API (fallback only) | $5-15 |
| Windows MSI | ‚úÖ Via Mac Mini Ollama (FREE) | Sonnet/Opus fallback only | $5-15 |

**Total estimated**: $60-130/month (down from $300+ before local LLMs)

---

## üìã Quick Reference: Which Machine for What?

| Task | Machine | Why |
|------|---------|-----|
| Main chat session | MacBook | Opus 4.5 (thinking=low) + orchestration |
| Sub-agent coding | MacBook | qwen3:8b (reasoning=true), devstral-24b (48GB RAM) |
| Heartbeats | Mac Mini | Always-on, qwen3:8b (reasoning=true, FREE) |
| Game servers (Aphos) | Mac Mini | pm2, always-on |
| **Trading bot (Shitcoin)** | **MacBook** | **48GB RAM for heavy models** |
| iOS builds | Mac Mini | Xcode, simulators |
| Bot dashboard | Mac Mini | clawd-monitor:9009 |
| Windows tasks | Windows MSI | Only Windows machine |
| Self-healing | MacBook + Mac Mini | event-watcher + Healer Bot v3 (swap monitoring) |

---

## üìö References

- [Clawdbot Config](../clawdbot-config.md) ‚Äî Model routing details
- [Ollama Setup](../ollama-setup.md) ‚Äî Local LLM configuration
- [Tailscale](../tailscale.md) ‚Äî Network configuration
- [SSH Config](../ssh-config.md) ‚Äî SSH setup
- [Dev Teams](../dev-teams.md) ‚Äî Bot roles per project
- [Hybrid Healing](../clawdbot/HYBRID-HEALING.md) ‚Äî Self-healing architecture
